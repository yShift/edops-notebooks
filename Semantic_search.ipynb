{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0dVvm7HNSaLw"
      },
      "source": [
        "# Comparing KNN and ANN search techniques\n",
        "\n",
        "Let's take a look at how the semantic search works. We will consider KNN and Ann searches with Euclidean and Cosine similarity metrics both. This notebook will find the most similar sentence to the given query from the list of sentences.\n",
        "\n",
        "Loading necessary libraries:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "uo0RjUbTh8q0"
      },
      "outputs": [],
      "source": [
        "!pip install sentence-transformers==2.5.1\n",
        "!pip install annoy==1.17.3\n",
        "!pip install faiss-cpu==1.8.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mFhSNPCGSb7k"
      },
      "source": [
        "Importing libraries and defining the sentences:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "1t5yEjxKiCYj"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "import numpy as np\n",
        "import faiss\n",
        "\n",
        "# Load the BAAI model for embeddings\n",
        "model = SentenceTransformer('BAAI/bge-small-en-v1.5')\n",
        "\n",
        "# Define sentences\n",
        "sentences = [\n",
        "    \"Assessing the functionality of different embedding models.\",\n",
        "    \"Two approaches for creating embeddings are provided here.\",\n",
        "    \"Evaluating the performance of various types of embeddings.\",\n",
        "    \"Here, we are presented with two methods for generating embeddings.\",\n",
        "    \"Vector search leverages the power of LLMs to provide more relevant and context-aware search results\",\n",
        "    \"Vector search significantly improves the user's ability to find information.\",\n",
        "    \"K-nearest neighbors is the exact search, which uses a brute force method to find nearest neighbors.\",\n",
        "    \"Approximate nearest neighbors trades accuracy for speed gains.\",\n",
        "    \"How to measure if two vectors are similar?\",\n",
        "    \"The most popular techniques are Euclidean and cosine metrics.\",\n",
        "    \"Euclidean Distance measures the physical distance between vectors.\",\n",
        "    \"The lower the Euclidean distance, the more similar the items are.\",\n",
        "    \"If the Euclidean distance is 0, the points are identical.\",\n",
        "    \"As the Euclidean distance increases, the points are considered to be less similar.\",\n",
        "    \"Cosine Similarity measures the angle between vectors, focusing on the direction rather than the magnitude.\",\n",
        "    \"The higher the cosine similarity, the more similar the items are.\",\n",
        "    \"Cosine similarity ranges from -1 to 1, where 1 means the vectors are identical.\"\n",
        "]\n",
        "\n",
        "# Generate embeddings\n",
        "embeddings = model.encode(sentences)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LV0ZGAN5jgrT"
      },
      "source": [
        "## KNN Search\n",
        "The knn_search function performs a k-nearest neighbors search to find the most similar sentences to a given query sentence within a list of sentences. It first encodes the query sentence into an embedding using a pre-trained model. Then, it applies the KNN algorithm, using the specified distance metric, to identify the nearest neighbors among the pre-computed embeddings of the sentences. The function prints the most similar sentence to the query, excluding the query itself if it appears in the sentence list, along with the distance indicating how similar they are. The search considers the `n_neighbors=5` closest neighbors but stops after identifying the first most relevant sentence."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "v26JZ3E2jhPY"
      },
      "outputs": [],
      "source": [
        "# Function to perform KNN search\n",
        "def knn_search(query, embeddings, sentences, metric):\n",
        "    # Generate the embedding for the query sentence\n",
        "    query_embedding = model.encode([query])\n",
        "    # Use KNN to find the most similar sentence\n",
        "    knn = NearestNeighbors(n_neighbors=2, metric=metric)\n",
        "    knn.fit(embeddings)\n",
        "    distances, indices = knn.kneighbors(query_embedding)\n",
        "    for i, index in enumerate(indices[0]):\n",
        "        if i == 0 and query in sentences:  # Skip the query itself if it's in the list\n",
        "            continue\n",
        "        if metric == 'cosine':\n",
        "            print(\n",
        "                f\"Most similar sentence: {sentences[index]} (Distance: {1-distances[0][i]})\")\n",
        "        else:\n",
        "            print(\n",
        "                f\"Most similar sentence: {sentences[index]} (Distance: {distances[0][i]})\")\n",
        "        break  # Break after finding the first relevant result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z6FIDAOgbO7N"
      },
      "source": [
        "Sometimes the number calculated for the cosine similarity actually presents `1-cosine_similarity`. That's why here we print the value `1-distance`, so it is compatible with this number for ANN search."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YaDU1B4oji__"
      },
      "source": [
        "## ANN Search and FAISS\n",
        "The ann_search function conducts an ANN search to identify the most similar sentence to a given query from a list of sentences. It leverages FAISS to perform the search with the choice of either Euclidean or cosine distance metrics.\n",
        "\n",
        "For cosine similarity, it normalizes both the embeddings and the query. The function then adds the embeddings to a FAISS index, conducts the search, and prints the closest sentence and its associated distance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "kX8_lP53QD9R"
      },
      "outputs": [],
      "source": [
        "# Function to perform ANN search\n",
        "def ann_search(query, embeddings, sentences, metric):\n",
        "    k = 2\n",
        "    dimension = embeddings.shape[1]\n",
        "\n",
        "    # Selecting the index type based on the metric\n",
        "    if metric == 'euclidean':\n",
        "        index = faiss.IndexFlatL2(dimension)\n",
        "    elif metric == 'cosine':\n",
        "        # Using inner product for cosine similarity\n",
        "        index = faiss.IndexFlatIP(dimension)\n",
        "\n",
        "    assert index.is_trained\n",
        "    index.add(embeddings)  # Adding the embeddings to the index\n",
        "\n",
        "    # Normalize query embedding for cosine similarity\n",
        "    query_embedding = model.encode([query]).astype(np.float32)\n",
        "    if metric == 'cosine':\n",
        "        faiss.normalize_L2(query_embedding)\n",
        "\n",
        "    # Perform the search\n",
        "    distances, indices = index.search(query_embedding, k)\n",
        "\n",
        "    for i, idx in enumerate(indices[0]):\n",
        "        # Skip the query itself if it's in the list\n",
        "        if i == 0 and metric == 'cosine' and sentences[idx] == query:\n",
        "            continue\n",
        "        print(\n",
        "            f\"Most similar sentence: {sentences[idx]} (Distance: {distances[0][i]})\")\n",
        "        break  # Break after finding the first relevant result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L6XNuZfxjikZ"
      },
      "source": [
        "Let's take a look at the final result:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WY_kCOq5jiVU",
        "outputId": "52108e79-5b26-406a-cca0-de0de1117afd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Query: Our next subject will be Vector Databases.\n",
            "---------------------------------------------\n",
            "KNN Search\n",
            "\n",
            "Euclidean Distance Results:\n",
            "Most similar sentence: Vector search significantly improves the user's ability to find information. (Distance: 0.7374712421176788)\n",
            "\n",
            "Cosine Distance Results:\n",
            "Most similar sentence: Vector search significantly improves the user's ability to find information. (Distance: 0.7280680537223816)\n",
            "---------------------------------------------\n",
            "ANN Search\n",
            "\n",
            "Euclidean Distance Results:\n",
            "Most similar sentence: Vector search significantly improves the user's ability to find information. (Distance: 0.5438637733459473)\n",
            "\n",
            "Cosine Distance Results:\n",
            "Most similar sentence: Vector search significantly improves the user's ability to find information. (Distance: 0.7280681729316711)\n",
            "---------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "query = \"Our next subject will be Vector Databases.\"\n",
        "print(f\"Query: {query}\")\n",
        "print(\"---------------------------------------------\")\n",
        "# Perform and display results with Euclidean distance\n",
        "print(\"KNN Search\")\n",
        "print(\"\\nEuclidean Distance Results:\")\n",
        "knn_search(query, embeddings, sentences, 'euclidean')\n",
        "\n",
        "# Perform and display results with Cosine distance\n",
        "print(\"\\nCosine Distance Results:\")\n",
        "knn_search(query, embeddings, sentences, 'cosine')\n",
        "\n",
        "print(\"---------------------------------------------\")\n",
        "print(\"ANN Search\")\n",
        "# Perform and display results with Euclidean distance\n",
        "print(\"\\nEuclidean Distance Results:\")\n",
        "ann_search(query, embeddings, sentences, 'euclidean')\n",
        "\n",
        "# Perform and display results with Cosine distance\n",
        "print(\"\\nCosine Distance Results:\")\n",
        "ann_search(query, embeddings, sentences, 'cosine')\n",
        "\n",
        "print(\"---------------------------------------------\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YIXnTTpojh-N"
      },
      "source": [
        "All methods (KNN and ANN, using both Euclidean and cosine distances) identified the same sentence as the most similar, suggesting a strong semantic connection between the query and this particular sentence.\n",
        "* **Euclidean Distance:** The distance values differ between KNN and ANN, which is expected as ANN provides an approximation.\n",
        "* **Cosine Distance:** The distances for cosine similarity are nearly identical across KNN and ANN, suggesting that for this metric and query, the ANN approximation closely matches the exact KNN result."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
